{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as P\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data = pd.read_csv('Data/titanic_full.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['nSex'] = data['sex'].map({'female':0, 'male':1}).astype(int)\n",
    "data['nEmbarked'] = data['embarked'].map({'S':0, 'C':1, 'Q':2})\n",
    "data.loc[(data.nEmbarked.isnull())] = 0\n",
    "data['nFamilySize'] = data['sibsp'] + data['parch']\n",
    "median_ages = np.zeros((2,3))\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_ages[i,j] = data[(data['nSex'] == i) & (data['pclass'] == j+1)]['age'].dropna().median()\n",
    "data['nAge'] = data['age']\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata.loc[(data.age.isnull()) & (data.nSex == i) & (data.pclass == j+1),'nAge'] = median_ages[i,j]\n",
    "median_fare = np.zeros((1,3))\n",
    "for i in range(0,1):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_fare[i,j] = data[(data['pclass'] == j+1) & (data['fare'] != 0)]['age'].median()\n",
    "data['nFare'] = data['fare']\n",
    "for i in range(0,1):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata.loc[((data.fare.isnull()) | (data.fare == 0)) & (data.pclass == j+1),'nFare'] = median_fare[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = data[['survived','nSex','nEmbarked','pclass']]\n",
    "ratioTable = pd.DataFrame({'actual': pd.Series([float(0)], index=['overall','men','women','class 1','class 2','class 3','embarked S', 'embarked C', 'embarked Q'])})\n",
    "ratioTable.actual[0] = float(data.survived.sum())/data.shape[0]\n",
    "ratioTable.actual[1] = float(data[(data['nSex'] == 1)]['survived'].sum())/data.shape[0]\n",
    "ratioTable.actual[2] = float(data[(data['nSex'] == 0)]['survived'].sum())/data.shape[0]\n",
    "ratioTable.actual[3] = float(data[(data['pclass'] == 1)]['survived'].sum())/data.shape[0]\n",
    "ratioTable.actual[4] = float(data[(data['pclass'] == 2)]['survived'].sum())/data.shape[0]\n",
    "ratioTable.actual[5] = float(data[(data['pclass'] == 3)]['survived'].sum())/data.shape[0]\n",
    "ratioTable.actual[6] = float(data[(data['nEmbarked'] == 0)]['survived'].sum())/data.shape[0]\n",
    "ratioTable.actual[7] = float(data[(data['nEmbarked'] == 1)]['survived'].sum())/data.shape[0]\n",
    "ratioTable.actual[8] = float(data[(data['nEmbarked'] == 2)]['survived'].sum())/data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model 1 (Random Forrest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1traindata = data[['survived','nSex','nEmbarked','nFamilySize','nAge','nFare','pclass']]\n",
    "model1traindata = model1traindata.astype(int)\n",
    "model1traindata = model1traindata.values\n",
    "\n",
    "model1testdata = data[['nSex','nEmbarked','nFamilySize','nAge','nFare','pclass']]\n",
    "model1testdata = model1testdata.astype(int)\n",
    "model1testdata = model1testdata.values\n",
    "\n",
    "model1forest = RandomForestClassifier(n_estimators = 1300)\n",
    "model1forest = model1forest.fit(model1traindata[0::,1::],model1traindata[0::,0])\n",
    "model1output = pd.DataFrame(model1forest.predict(model1testdata))\n",
    "model1output['nSex'] = data[['nSex']]\n",
    "model1output['nEmbarked'] = data[['nEmbarked']]\n",
    "model1output['pclass'] = data[['pclass']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Creating Model 2 (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2traindataX = data[['nSex','nEmbarked','nFamilySize','nAge','nFare','pclass']]\n",
    "model2traindataX = model2traindataX.astype(int)\n",
    "model2traindataX = model2traindataX.values\n",
    "model2traindatay = data[['survived']]\n",
    "model2traindatay = np.ravel(model2traindatay)\n",
    "\n",
    "model2testdata = data[['nSex','nEmbarked','nFamilySize','nAge','nFare','pclass']]\n",
    "model2testdata = model2testdata.astype(int)\n",
    "model2testdata = model2testdata.values\n",
    "\n",
    "model2LogisticRegression = LogisticRegression()\n",
    "model2LogisticRegression = model2LogisticRegression.fit(model2traindataX,model2traindatay)\n",
    "model2output = pd.DataFrame(model2LogisticRegression.predict(model2testdata))\n",
    "model2output['nSex'] = data[['nSex']]\n",
    "model2output['nEmbarked'] = data[['nEmbarked']]\n",
    "model2output['pclass'] = data[['pclass']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model 3 (Support Vector Machines)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3traindataX = data[['nSex','nEmbarked','nFamilySize','nAge','nFare','pclass']]\n",
    "model3traindataX = model3traindataX.astype(int)\n",
    "model3traindataX = model3traindataX.values\n",
    "model3traindatay = data[['survived']]\n",
    "model3traindatay = np.ravel(model3traindatay)\n",
    "\n",
    "model3testdata = data[['nSex','nEmbarked','nFamilySize','nAge','nFare','pclass']]\n",
    "model3testdata = model3testdata.astype(int)\n",
    "model3testdata = model3testdata.values\n",
    "\n",
    "model3LogisticRegression = SVC()\n",
    "model3LogisticRegression = model3LogisticRegression.fit(model3traindataX,model3traindatay)\n",
    "model3output = pd.DataFrame(model3LogisticRegression.predict(model2testdata))\n",
    "model3output['nSex'] = data[['nSex']]\n",
    "model3output['nEmbarked'] = data[['nEmbarked']]\n",
    "model3output['pclass'] = data[['pclass']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              actual    model1    model2    model3\n",
      "overall     0.380443  0.361345  0.341482  0.315508\n",
      "men         0.122995  0.091673  0.017571  0.072574\n",
      "women       0.257448  0.269672  0.323911  0.242934\n",
      "class 1     0.151261  0.146677  0.126050  0.145913\n",
      "class 2     0.090909  0.090909  0.080214  0.074102\n",
      "class 3     0.138273  0.123759  0.133690  0.095493\n",
      "embarked S  0.232238  0.212376  0.198625  0.177998\n",
      "embarked C  0.114591  0.112299  0.097785  0.103896\n",
      "embarked Q  0.033613  0.036669  0.045073  0.033613\n"
     ]
    }
   ],
   "source": [
    "ratioTable['model1'] = float(0)\n",
    "ratioTable.model1[0] = float(model1output[0].sum())/model1output.shape[0]\n",
    "ratioTable.model1[1] = float(model1output[(model1output['nSex'] == 1)][0].sum())/model1output.shape[0]\n",
    "ratioTable.model1[2] = float(model1output[(model1output['nSex'] == 0)][0].sum())/model1output.shape[0]\n",
    "ratioTable.model1[3] = float(model1output[(model1output['pclass'] == 1)][0].sum())/model1output.shape[0]\n",
    "ratioTable.model1[4] = float(model1output[(model1output['pclass'] == 2)][0].sum())/model1output.shape[0]\n",
    "ratioTable.model1[5] = float(model1output[(model1output['pclass'] == 3)][0].sum())/model1output.shape[0]\n",
    "ratioTable.model1[6] = float(model1output[(model1output['nEmbarked'] == 0)][0].sum())/model1output.shape[0]\n",
    "ratioTable.model1[7] = float(model1output[(model1output['nEmbarked'] == 1)][0].sum())/model1output.shape[0]\n",
    "ratioTable.model1[8] = float(model1output[(model1output['nEmbarked'] == 2)][0].sum())/model1output.shape[0]\n",
    "\n",
    "ratioTable['model2'] = float(0)\n",
    "ratioTable.model2[0] = float(model2output[0].sum())/model2output.shape[0]\n",
    "ratioTable.model2[1] = float(model2output[(model2output['nSex'] == 1)][0].sum())/model2output.shape[0]\n",
    "ratioTable.model2[2] = float(model2output[(model2output['nSex'] == 0)][0].sum())/model2output.shape[0]\n",
    "ratioTable.model2[3] = float(model2output[(model2output['pclass'] == 1)][0].sum())/model2output.shape[0]\n",
    "ratioTable.model2[4] = float(model2output[(model2output['pclass'] == 2)][0].sum())/model2output.shape[0]\n",
    "ratioTable.model2[5] = float(model2output[(model2output['pclass'] == 3)][0].sum())/model2output.shape[0]\n",
    "ratioTable.model2[6] = float(model2output[(model2output['nEmbarked'] == 0)][0].sum())/model2output.shape[0]\n",
    "ratioTable.model2[7] = float(model2output[(model2output['nEmbarked'] == 1)][0].sum())/model2output.shape[0]\n",
    "ratioTable.model2[8] = float(model2output[(model2output['nEmbarked'] == 2)][0].sum())/model2output.shape[0]\n",
    "\n",
    "ratioTable['model3'] = float(0)\n",
    "ratioTable.model3[0] = float(model3output[0].sum())/model3output.shape[0]\n",
    "ratioTable.model3[1] = float(model3output[(model3output['nSex'] == 1)][0].sum())/model3output.shape[0]\n",
    "ratioTable.model3[2] = float(model3output[(model3output['nSex'] == 0)][0].sum())/model3output.shape[0]\n",
    "ratioTable.model3[3] = float(model3output[(model3output['pclass'] == 1)][0].sum())/model3output.shape[0]\n",
    "ratioTable.model3[4] = float(model3output[(model3output['pclass'] == 2)][0].sum())/model3output.shape[0]\n",
    "ratioTable.model3[5] = float(model3output[(model3output['pclass'] == 3)][0].sum())/model3output.shape[0]\n",
    "ratioTable.model3[6] = float(model3output[(model3output['nEmbarked'] == 0)][0].sum())/model3output.shape[0]\n",
    "ratioTable.model3[7] = float(model3output[(model3output['nEmbarked'] == 1)][0].sum())/model3output.shape[0]\n",
    "ratioTable.model3[8] = float(model3output[(model3output['nEmbarked'] == 2)][0].sum())/model3output.shape[0]\n",
    "\n",
    "print ratioTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Confusion Matrix\n",
      "[[788  23]\n",
      " [ 48 450]]\n",
      "Model 2 Confusion Matrix\n",
      "[[700 111]\n",
      " [162 336]]\n",
      "Model 3 Confusion Matrix\n",
      "[[776  35]\n",
      " [120 378]]\n"
     ]
    }
   ],
   "source": [
    "print 'Model 1 Confusion Matrix'\n",
    "print confusion_matrix(actual['survived'], model1output[0])\n",
    "print 'Model 2 Confusion Matrix'\n",
    "print confusion_matrix(actual['survived'], model2output[0])\n",
    "print 'Model 3 Confusion Matrix'\n",
    "print confusion_matrix(actual['survived'], model3output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_file = open(\"model1.csv\", \"wb\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"Survived\"])\n",
    "open_file_object.writerows(zip(model1output))\n",
    "predictions_file.close()\n",
    "\n",
    "predictions_file = open(\"model2.csv\", \"wb\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"Survived\"])\n",
    "open_file_object.writerows(zip(model2output))\n",
    "predictions_file.close()\n",
    "\n",
    "predictions_file = open(\"model3.csv\", \"wb\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"Survived\"])\n",
    "open_file_object.writerows(zip(model3output))\n",
    "predictions_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
