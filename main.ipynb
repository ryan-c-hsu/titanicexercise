{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import pylab as P\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing Titanic Data\n",
    "data = pd.read_csv('Data/titanic_full.csv', header=0)\n",
    "\n",
    "# Converting to numbers - Sex, Family Size, and Embarked\n",
    "data['nSex'] = data['sex'].map({'female':0, 'male':1})\n",
    "dummies = pd.get_dummies(data['embarked']).astype(float)\n",
    "data = pd.concat([data, dummies], axis=1)\n",
    "data['nFamilySize'] = data['sibsp'] + data['parch']\n",
    "\n",
    "# To Fill in Age according to Sex and Class\n",
    "median_ages = np.zeros((2,3))\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_ages[i,j] = data[(data['nSex'] == i) & (data['pclass'] == j+1)]['age'].dropna().median()\n",
    "data['nAge'] = data['age']\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata.loc[(data.age.isnull()) & (data.nSex == i) & (data.pclass == j+1),'nAge'] = median_ages[i,j]\n",
    "median_fare = np.zeros((1,3))\n",
    "\n",
    "# To Fill in Fare according to Class\n",
    "for i in range(0,1):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_fare[i,j] = data[(data['pclass'] == j+1) & (data['fare'] != 0)]['age'].median()\n",
    "data['nFare'] = data['fare']\n",
    "for i in range(0,1):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata.loc[((data.fare.isnull()) | (data.fare == 0)) & (data.pclass == j+1),'nFare'] = median_fare[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Comment \n",
    "#Split up data set (70 Train, 30 Split - sklearn train test split)\n",
    "train, test = train_test_split( data, test_size=0.3, random_state=42)\n",
    "\n",
    "traindata = train[['survived','nSex','S', 'C', 'Q','nFamilySize','nAge','nFare','pclass']]\n",
    "traindata = traindata.values\n",
    "traindataX = train[['nSex','S', 'C', 'Q','nFamilySize','nAge','nFare','pclass']]\n",
    "traindataX = traindataX.values\n",
    "traindataY = train[['survived']]\n",
    "traindataY = np.ravel(traindataY)\n",
    "\n",
    "testdataF = pd.DataFrame(test[['nSex','S', 'C', 'Q','nFamilySize','nAge','nFare','pclass']])\n",
    "testdata = testdataF.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model 1 (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Comment \n",
    "#Split up data set (70 Train, 30 Split - sklearn train test split)\n",
    "forest = RandomForestClassifier(n_estimators = 1300)\n",
    "forest = forest.fit(traindata[0::,1::],traindata[0::,0])\n",
    "forestOutput = pd.DataFrame(forest.predict(testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Creating Model 2 (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logisticRegression = LogisticRegression()\n",
    "logisticRegression = logisticRegression.fit(traindataX,traindataY)\n",
    "logisticRegressionOutput = pd.DataFrame(logisticRegression.predict(testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model 3 (Support Vector Machines)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supportVC = SVC()\n",
    "supportVC = supportVC.fit(traindataX,traindataY)\n",
    "supportVCOutput = pd.DataFrame(supportVC.predict(testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Random_Forrest  Logistic_Regression  \\\n",
      "Accuracy                   0.788804             0.801527   \n",
      "F1 Binary                  0.739812             0.740000   \n",
      "Mean Absolute Error        0.211196             0.198473   \n",
      "R^2                        0.138340             0.190247   \n",
      "\n",
      "                     Support_Vector_Machines  \n",
      "Accuracy                            0.661578  \n",
      "F1 Binary                           0.523297  \n",
      "Mean Absolute Error                 0.338422  \n",
      "R^2                                -0.380732  \n"
     ]
    }
   ],
   "source": [
    "# Saving the True Surviving Data\n",
    "actual = test[['survived']]\n",
    "\n",
    "# Tale showing the different evaluations of each Model\n",
    "model1 = forestOutput[0]\n",
    "model2 = logisticRegressionOutput[0]\n",
    "model3 = supportVCOutput[0]\n",
    "ratioTable = pd.DataFrame({'Random_Forrest': pd.Series([float(0)], index=['Accuracy','F1 Binary','Mean Absolute Error', 'R^2'])})\n",
    "ratioTable.Random_Forrest[0] = accuracy_score(actual, model1)\n",
    "ratioTable.Random_Forrest[1] = f1_score(actual, model1, average='binary')\n",
    "ratioTable.Random_Forrest[2] = mean_absolute_error(actual, model1)\n",
    "ratioTable.Random_Forrest[3] = r2_score(actual, model1)\n",
    "ratioTable['Logistic_Regression'] = float(0)\n",
    "ratioTable.Logistic_Regression[0] = accuracy_score(actual, model2)\n",
    "ratioTable.Logistic_Regression[1] = f1_score(actual, model2, average='binary')\n",
    "ratioTable.Logistic_Regression[2] = mean_absolute_error(actual, model2)\n",
    "ratioTable.Logistic_Regression[3] = r2_score(actual, model2)\n",
    "ratioTable['Support_Vector_Machines'] = float(0)\n",
    "ratioTable.Support_Vector_Machines[0] = accuracy_score(actual, model3)\n",
    "ratioTable.Support_Vector_Machines[1] = f1_score(actual, model3, average='binary')\n",
    "ratioTable.Support_Vector_Machines[2] = mean_absolute_error(actual, model3)\n",
    "ratioTable.Support_Vector_Machines[3] = r2_score(actual, model3)\n",
    "\n",
    "print ratioTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance for Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. nSex (0.294356)\n",
      "2. S (0.272687)\n",
      "3. C (0.234407)\n",
      "4. Q (0.081855)\n",
      "5. nFamilySize (0.079585)\n",
      "6. nAge (0.018361)\n",
      "7. nFare (0.013006)\n",
      "8. pclass (0.005742)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(8):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, testdataF.columns.values[f], importances[indices[f]]))\n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(8), importances[indices],color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(8), testdataF.columns.values)\n",
    "plt.xlim([-1, 8])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Model 1 Confusion Matrix'\n",
    "print confusion_matrix(actual['survived'], model1output[0])\n",
    "print 'Model 2 Confusion Matrix'\n",
    "print confusion_matrix(actual['survived'], model2output[0])\n",
    "print 'Model 3 Confusion Matrix'\n",
    "print confusion_matrix(actual['survived'], model3output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_file = open(\"model1.csv\", \"wb\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"Survived\"])\n",
    "open_file_object.writerows(zip(model1output))\n",
    "predictions_file.close()\n",
    "\n",
    "predictions_file = open(\"model2.csv\", \"wb\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"Survived\"])\n",
    "open_file_object.writerows(zip(model2output))\n",
    "predictions_file.close()\n",
    "\n",
    "predictions_file = open(\"model3.csv\", \"wb\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"Survived\"])\n",
    "open_file_object.writerows(zip(model3output))\n",
    "predictions_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
